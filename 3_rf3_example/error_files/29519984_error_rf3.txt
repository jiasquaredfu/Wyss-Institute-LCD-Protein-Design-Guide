10:47:26 DEBUG transforms: Debug mode is on
10:47:27 INFO rf3.inference_engines.rf3: [rank: 0] Loading checkpoint from /n/data1/hms/wyss/collins/lab/software/1_backbone_design/foundry/checkpoints/rf3_foundry_01_24_latest.ckpt...
10:47:35 WARNING atomworks.ml: Using element type for atom names of atomized tokens.
Using bfloat16 Automatic Mixed Precision (AMP)
You are using a CUDA device ('NVIDIA L40S') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
10:47:38 INFO rf3.inference_engines.rf3: [rank: 0] Outputs will be written to /n/data1/hms/wyss/collins/lab/users/jiajia/3_rf3/hiv_ex/output.
10:47:41 INFO rf3.inference_engines.rf3: [rank: 0] Found 1 structures to predict!
10:47:41 INFO rf3.inference_engines.rf3: [rank: 0] Predicting structure 1/1: hiv_receptor
10:47:49 INFO rf3.inference_engines.rf3: [rank: 0] Outputs for hiv_receptor written to /n/data1/hms/wyss/collins/lab/users/jiajia/3_rf3/hiv_ex/output/hiv_receptor!
